# Logistic Regression

```{r}
# Load libraries
library(tidyr); library(dplyr); library(ggplot2); library(GGally)

# Import data
alc <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt ", sep=",", header=TRUE)
```

*WRITE ME >> The data used in this analysis is...A description of the variables in the dataset includes... The data has 382 observations and 35 variables as well as 166 rows and 7 columns.*


```{r}
str(alc)
dim(alc)
```

#### Analysis of variables
*WRITE ME >> choose 4 variables present your personal hypothesis about their relationships with alcohol consumption: The four variables that I chose were: age, failures, Dalc, absences.*

*hypothesese:* 
*sex -- boys more likely to drink*
*failures -- more failures more likely to drink*
*Dalc -- drinking during the week more likely to drink more aka problem drinking (not just doing it socially)*
*absenses -- missing more school, more likely to drink more (unless of course sick due to illness)*
```{r}
data(alc, package = "COUNT")
attach(alc)
table(high_use, sex)
table(high_use, failures)
table(high_use, Dalc)
table(high_use, absences)

```



```{r}
g2 <- ggplot(alc, aes(x = high_use, y = failures, col = sex))
g2 + geom_boxplot() + ylab("grade") + ggtitle("Student failures by alcohol consumption and sex")

g3 <- ggplot(alc, aes(x = high_use, y = Dalc, col = sex))
g3 + geom_boxplot() + ylab("grade") + ggtitle("Student work day alcohol consumption by alcohol consumption and sex")

g4 <- ggplot(alc, aes(x = high_use, y = absences, col = sex))
g4 + geom_boxplot() + ylab("grade") + ggtitle("Student absences by alcohol consumption and sex")

```

```{r}
gather(alc) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()
```

*WRITE ME >> Comment on your findings and compare the results of your exploration to your previously stated hypotheses.*


### Logistic regression
```{r}
# find the model with glm()
m <- glm(high_use ~ failures + absences + sex + Dalc, data = alc, family = "binomial")

# print out a summary of the model
summary(m)

# print out the coefficients of the model
coef(m)
```

```{r}
# compute odds ratios (OR)
OR <- coef(m) %>% exp

# compute confidence intervals (CI)
CI <- confint(m) %>% exp

# print out the odds ratios with their confidence intervals
cbind(OR, CI)

```

#### Analysis of the model
*WRITE ME >> 1) Present and interpret a summary of the fitted model. 2) Present and interpret the coefficients of the model as odds ratios and provide confidence intervals for them. Interpret the results and compare them to your previously stated hypothesis.*



#### Make predictions
```{r}
# fit the model
m <- glm(high_use ~ absences + Dalc, data = alc, family = "binomial")

# predict() the probability of high_use
probabilities <- predict(m, type = "response")

# add the predicted probabilities to 'alc'
alc <- mutate(alc, probability = probabilities)

# use the probabilities to make a prediction of high_use
alc <- mutate(alc, prediction = probability > 0.5)

# see the last ten original classes, predicted probabilities, and class predictions
select(alc, absences, Dalc, high_use, probability, prediction) %>% tail(10)

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = probabilities > 0.5)
```

```{r}
# initialize a plot of 'high_use' versus 'probability' in 'alc'
g <- ggplot(alc, aes(x = probability, y = high_use, col = prediction))

# define the geom as points and draw the plot
g + geom_point()

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table() %>% addmargins()
```

#### Accuracy of model
```{r}
# define a loss function (mean prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# call loss_func to compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = alc$probability)
```


```{r}
# define a loss function (average prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = alc$probability)
```


### 10 fold cross-validation
```{r}
# K-fold cross-validation
library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)

# average number of wrong predictions in the cross validation
cv$delta[1]
```


### Analysis of predictions
*Compute the total proportion of inaccurately classified individuals (= the training error) and comment on all the results. Compare the performance of the model with performance achieved by some simple guessing strategy.*