print("hello world!")
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
install.packages("rmarkdown")
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
summary(lrn14)
print(lrn14)
dim(lrn14)
str(lrn14)
library(dplyr)
install.packages("dplyr")
library(dplyr)
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
keep_columns <- c("gender","Age","attitude", "deep", "stra", "surf", "Points")
# select the 'keep_columns' to create a new dataset
learning2014 <- select(lrn14, one_of(keep_columns))
# see the stucture of the new dataset
str(learning2014)
summary(learning2014)
learning2014 <- filter(learning2014, points = 0)
# Exclude observations where the exam points variable is zero
learning2014 <- filter(learning2014, points == 0)
learning2014 <- filter(learning2014, Points == 0)
summary(learning2014)
dim(learning2014)
str(learning2014)
learning2014 <- filter(learning2014, Points > 0)
str(learning2014)
learning2014 <- filter(learning2014, Points < 0)
str(learning2014)
# Gabrielle Mantell - 06 November 2018
# IODS 2018 R Studio Exercise 2
# Read the full learning2014 data
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# Explore the structure and dimensions of the data
dim(lrn14) # this dataset consists of 183 rows and 60 columns
str(lrn14) # and 183 obs. of  60 variables
# Access the dplyr library
library(dplyr)
# Create an analysis dataset with the variables gender, age, attitude, deep, stra, surf and points
# by combining questions in the learning2014 data
# Combine questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# choose columns to keep
keep_columns <- c("gender","Age","attitude", "deep", "stra", "surf", "Points")
# select the 'keep_columns' to create a new dataset
learning2014 <- select(lrn14, one_of(keep_columns))
# Exclude observations where the exam points variable is zero
learning2014 <- filter(learning2014, Points < 0)
str(learning2014)
# Read the full learning2014 data
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# Explore the structure and dimensions of the data
dim(lrn14) # this dataset consists of 183 rows and 60 columns
str(lrn14) # and 183 obs. of  60 variables
# Create an analysis dataset with the variables gender, age, attitude, deep, stra, surf and points
# by combining questions in the learning2014 data
library(dplyr)
# Combine questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# choose columns to keep
keep_columns <- c("gender","Age","attitude", "deep_columns", "stra_columns", "surf_columns", "Points")
# select the 'keep_columns' to create a new dataset
learning2014 <- select(lrn14, one_of(keep_columns))
# Exclude observations where the exam points variable is zero
learning2014 <- filter(learning2014, Points == 0)
str(learning2014)
lrn14 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", sep=",", header=TRUE)
lrn14 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", sep=",", header=TRUE)
str(lrn14)
dim(lrn14)
lrn14 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", sep=",", header=TRUE)
pairs(learning2014)
pairs(lrn14)
pairs(learning2014[-1])
pairs(lrn14[-1])
str(lrn14$gender)
summary(lrn14$gender)
head(lrn14)
?head
ggpairs(lrn14, lower = list(combo = wrap("facethist", bins = 20)))
library(GGally)
library(ggplot2)
install.packages("GGally")
install.packages("ggplot2")
library(GGally)
library(ggplot2)
library(ggplot2)
library(GGally)
ggpairs(lrn14, lower = list(combo = wrap("facethist", bins = 20)))
# create a regression model with multiple explanatory variables
model1 <- lm(points ~ attitude + stra + surf, data = lrn2014)
# print out a summary of the model
summary(model1)
model1 <- lm(points ~ attitude + stra + surf, data = lrn2014)
# Regression and model validation
# ALL CODE
# Load libraries
library(GGally)
library(ggplot2)
# Import data
lrn14 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", sep=",", header=TRUE)
# About the data
str(lrn14)
dim(lrn14)
# draw a scatter plot matrix of the variables excluding the first column, gender
pairs(lrn14[-1])
# show summaries of the variables in the data.
summary(lrn14$gender)
summary(lrn14$age)
summary(lrn14$attitude)
summary(lrn14$deep)
summary(lrn14$stra)
summary(lrn14$surf)
summary(lrn14$points)
# create an plot matrix with ggpairs()
ggpairs(lrn14, lower = list(combo = wrap("facethist", bins = 20)))
# create a regression model with multiple explanatory variables
model1 <- lm(points ~ attitude + stra + surf, data = lrn2014)
# print out a summary of the model
summary(model1)
model1 <- lm(points ~ attitude + stra + surf, data = lrn14)
summary(model1)
# create a regression model with statistically relevant variables
model2 <- lm(points ~ attitude + stra, data = lrn14)
# print out a summary of the model
summary(model2)
# create a regression model with statistically relevant variables
model2 <- lm(points ~ attitude, data = lrn14)
# print out a summary of the model
summary(model2)
summary(lrn14$gender, lrn14$age, lrn14$attitude, lrn14$deep, lrn14$stra, lrn14$surf ,lrn14$points)
summary(lrn14)
summary(model2)
par(mfrow = c(2,2))
plot(model2, which = c(1:2,5))
**Residuals vs Fitted**
The Residuals vs Fitted plot is based on the assumption that the size of error doesn't depend on explanatory variables. The plot shows whether there is a problem with this assumption. There is no pattern in the data, therefore the model adheres to the assumption.
g2 <- ggplot(alc, aes(x = high_use, y = failures))
# Load libraries
library(tidyr); library(dplyr); library(ggplot2); library(GGally)
# Import data
alc <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt ", sep=",", header=TRUE)
g2 <- ggplot(alc, aes(x = high_use, y = failures))
g2 + geom_boxplot() + ylab("failures") + ggtitle("Student failures by alcohol consumption and sex")
p1 <- ggplot(alc, aes(x = high_use, y = failures, col = gender))
p2 <- p1 + geom_point()
p2
p1 <- ggplot(alc, aes(x = high_use, y = failures, col = sex))
p2 <- p1 + geom_point()
p2
p3 <- p2 + geom_smooth(method = "lm")
p3
100-94
100-9
library(MASS); library(tidyr); library(dplyr); library(ggplot2); library(GGally)
data("Boston")
str(data)
dim(data)
str(Boston)
dim(Boston)
summary(Boston)
```{r}
pairs(Boston)
pairs(Boston)
cor_matrix<-cor(Boston)
print(cor_matrix)
corrplot(cor_matrix, method="circle", type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6) %>% round(digits = 2)
library(tidyr); library(dplyr); library(ggplot2); library(GGally)
pairs(Boston)
cor_matrix<-cor(Boston)
print(cor_matrix)
corrplot(cor_matrix, method="circle", type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6) %>% round(digits = 2)
install.packages("corrplot")
pairs(Boston)
cor_matrix<-cor(Boston)
print(cor_matrix)
corrplot(cor_matrix, method="circle", type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6) %>% round(digits = 2)
library(MASS); library(tidyr); library(dplyr); library(ggplot2); library(GGally)
library(corrplot)
pairs(Boston)
cor_matrix<-cor(Boston)
print(cor_matrix)
corrplot(cor_matrix, method="circle", type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6) %>% round(digits = 2)
boston_scaled <- scale(Boston)
summary(boston_scaled)
class(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)
summary(boston_scaled$crim)
summary(boston_scaled$crim)
bins <- quantile(boston_scaled$crim)
bins
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))
table(crime)
boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
correct_classes <- test$crime
test <- dplyr::select(test, -crime)
lda.fit <- lda(crime ~ ., data = train)
lda.fit
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(lda.fit, col = classes, pch = classes, dimen = 2)
lda.arrows(lda.fit, myscale = 1)
# Load libraries
library(MASS); library(tidyr); library(dplyr); library(ggplot2); library(GGally); library(corrplot)
# Load data
data("Boston")
str(Boston)
summary(Boston)
pairs(Boston)
cor_matrix<-cor(Boston)
print(cor_matrix)
corrplot(cor_matrix, method="circle", type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6) %>% round(digits = 2)
boston_scaled <- scale(Boston)
summary(boston_scaled)
class(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)
summary(boston_scaled$crim)
bins <- quantile(boston_scaled$crim)
bins
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))
table(crime)
boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
lda.fit <- lda(crime ~ ., data = train)
lda.fit
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
lda.fit <- lda(crime ~ ., data = train)
lda.fit
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(lda.fit, col = classes, pch = classes, dimen = 2)
lda.arrows(lda.fit, myscale = 1)
correct_classes <- test$crime
test <- dplyr::select(test, -crime)
summary(boston_scaled$crim)
bins <- quantile(boston_scaled$crim)
bins
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))
table(crime)
boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
correct_classes <- test$crime
test <- dplyr::select(test, -crime)
lda.fit <- lda(crime ~ ., data = train)
lda.fit
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(lda.fit, col = classes, pch = classes, dimen = 2)
lda.arrows(lda.fit, myscale = 1)
lda.fit <- lda(crime ~ ., data = train)
lda.fit
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(lda.fit, col = classes, pch = classes, dimen = 2)
lda.arrows(lda.fit, myscale = 1)
library(MASS); library(tidyr); library(dplyr); library(ggplot2); library(GGally); library(corrplot)
# Load data
data("Boston")
str(Boston)
summary(Boston)
str(Boston)
summary(Boston)
# Load libraries
library(MASS); library(tidyr); library(dplyr); library(ggplot2); library(GGally); library(corrplot)
# Load data
data("Boston")
str(Boston)
summary(Boston)
pairs(Boston)
cor_matrix<-cor(Boston)
print(cor_matrix)
corrplot(cor_matrix, method="circle", type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6) %>% round(digits = 2)
boston_scaled <- scale(Boston)
summary(boston_scaled)
class(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)
summary(boston_scaled$crim)
bins <- quantile(boston_scaled$crim)
bins
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))
table(crime)
boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
correct_classes <- test$crime
test <- dplyr::select(test, -crime)
# Load libraries
library(MASS); library(tidyr); library(dplyr); library(ggplot2); library(GGally); library(corrplot)
# Load data
data("Boston")
str(Boston)
summary(Boston)
pairs(Boston)
cor_matrix<-cor(Boston)
print(cor_matrix)
corrplot(cor_matrix, method="circle", type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6) %>% round(digits = 2)
boston_scaled <- scale(Boston)
summary(boston_scaled)
class(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)
summary(boston_scaled$crim)
bins <- quantile(boston_scaled$crim)
bins
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))
table(crime)
boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
lda.fit <- lda(crime ~ ., data = train)
lda.fit
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(lda.fit, col = classes, pch = classes, dimen = 2)
lda.arrows(lda.fit, myscale = 1)
correct_classes <- test$crime
test <- dplyr::select(test, -crime)
RATSL <- read.csv("ratsl.csv", sep  =" ", header = T)
setwd("~/GitHub/IODS-project/data")
RATSL <- read.csv("ratsl.csv", sep  =" ", header = T)
RATSL <- read.csv("~/GitHub/IODS-project/data/ratsl.csv", sep  =" ", header = T)
RATSL <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/rats.txt", sep  =" ", header = T)
BPRSL <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/BPRS.txt", sep  =" ", header = T)
RATSL$ID <- factor(RATSL$ID)
RATSL$Group <- factor(RATSL$Group)
library(stringr); library(dplyr); library(GGally); library(corrplot); library(ggplot2); library(tidyr); library(MASS); library(boot); library(lme4)
RATSL <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/rats.txt", sep  =" ", header = T)
BPRSL <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/BPRS.txt", sep  =" ", header = T)
RATSL$ID <- factor(RATSL$ID)
RATSL$Group <- factor(RATSL$Group)
RATS$ID <- factor(RATS$ID)
RATS$ID <- factor(RATS$ID)
RATS <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/rats.txt", sep  =" ", header = T)
BPRSL <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/BPRS.txt", sep  =" ", header = T)
RATS$ID <- factor(RATS$ID)
RATS$Group <- factor(RATS$Group)
RATSL <- read.table("https://github.com/gabriellemantell/IODS-project/blob/master/data/ratsl.csv", header = T)
RATSL <- read.table("https://github.com/gabriellemantell/IODS-project/blob/master/data/ratsl.csv", sep = " ", header = T)
RATSL <- read.table("https://github.com/gabriellemantell/IODS-project/blob/master/data/ratsl.csv", sep = ",", header = T)
BPRSL <- read.table("https://github.com/gabriellemantell/IODS-project/blob/master/data/bprsl.csv", sep = ",", header = T)
RATSL <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/rats.txt", header = TRUE, sep = '\t')
RATSL$ID <- factor(RATSL$ID)
RATSL$Group <- factor(RATSL$Group)
str(RATSL)
RATS <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/rats.txt", header = TRUE, sep = '\t')
RATS$ID <- factor(RATS$ID)
RATS$Group <- factor(RATS$Group)
RATSL <- RATSL %>%
gather(key = WD, value = Weight, -ID, -Group) %>%
mutate(Time = as.integer(substr(WD,3,4)))
RATS$ID <- factor(RATS$ID)
RATS$Group <- factor(RATS$Group)
RATSL <- RATS %>%
gather(key = WD, value = Weight, -ID, -Group) %>%
mutate(Time = as.integer(substr(WD,3,4)))
str(RATSL)
ggplot(BPRSL, aes(x = week, y = bprs)) + geom_text(aes(linetype = treatment, label = treatment)) + scale_x_continuous(name = "Time (days)") + scale_y_continuous(name = "Weight (grams)") + theme(legend.position = "top")
BPRS <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/BPRS.txt", sep  =" ", header = T)
BPRS$treatment <- factor(BPRS$treatment)
BPRS$subject <- factor(BPRS$subject)
BPRSL <-  BPRS %>% gather(key = weeks, value = bprs, -treatment, -subject)
BPRSL <-  BPRSL %>% mutate(week = as.integer(substr(weeks,5,5)))
str(BPRSL)
ggplot(BPRSL, aes(x = week , y = bprs, linetype = subject)) +
geom_line() +
scale_linetype_manual(values = rep(1:10, times=4)) +
facet_grid(. ~ treatment, labeller = label_both) +
theme(legend.position = "none") +
scale_y_continuous(limits = c(min(BPRSL$bprs), max(BPRSL$bprs)))
View(BPRS)
